# Transform cell counts to brain coordinate space - Brains 8-11.
# muniak@ohsu.edu
# 2024.11.06 - output verified for manuscript.

# Custom script path (must contain rothetal_pkg folder).
PKG_PATH = r'<<FILEPATH_TO_SCRIPTS>>'

# Set location of data.
ROOT_DIR = r'<<FILEPATH_TO_DATA>>'

# 2024.02.24
""" FOR BRAINS 8-11 ONLY!!
    Hacky file to adjust the Cell Counter coordinates for Brains 8-11 because the
    image stacks those counts were based on were generated from the RAW OME-TIFFs
    _prior_ to alignment in TrakEM2 (unlike Brains 2-7, where the coordinates were
    in calibrated/aligned project space after factoring in the ROI crop offset).
    This was due to time constraints: Cierra, the counter, was leaving in a few days,
    and the full section series was not yet imaged, only the range through the thalamus.
    
    This meant that the cell coordinates required two adjustments:
    
    1) The Cell Counter image stack for Brains 8-11 was generated by first creating an
       image stack of all the OME-TIFFs, and then cropping out the relevant zone
       across the entire stack.  However, because each OME-TIFF had slightly different
       dimensions, the stacking operation in FIJI added padding to any sections that
       were smaller than the largest span of each dimension.  I dumbly created the image 
       stack by centering all of the images, rather than aligning to top-left... This had
       the unintended consequence that the relative offset of the ROI crop box to the 
       top-left corner of each specific image was different from the overall ROI offset--
       thus, each ROI had to be further adjusted by _half_ of the difference between the
       dimension size of the specific image, and the overall dimension span of the stack.
       This adjustment was pre-calculated in the Excel sheet.
    
    2) Once cell coordinates were adjusted with respect to top-left of each individual image,
       they were then transformed into aligned project space using the same affine transform
       associated with that image's representation in TrakEM2 (also factoring in any project
       downsampling).  This part is straightforward.
    
    *** NOTE REQUIRES COPYING IN BRAIN-SPECIFIC VALUES FROM EXCEL TABLES BELOW... ***
"""
### Copy over offsets {z:(x,y)} from script 4.b ("extract image dims.py""), formatted as dict.
offsets = {z1:(x1,y1), z2:(x2,y2), ...}

### Copy over slice,x,y cols from Cell Counter ResultsTable ("Measure...") as one long array (z1, x1, y1, z2, x2, y2, etc..)
xlsvals = [z1, x1, y1, x2, x2, y2, ...]

### Copy over offset vals from "roi_bounds_for_cell_count_stacks.xlsx"
zoff = 0
offsets_shift = 100 - zoff - 1  # This does not change.  When Richard imaged the subset of images, he started the count at #100 because the actual section # was not yet known.
xoff = 0
yoff = 0


import os
import sys
from array import array

sys.path.insert(0, PKG_PATH)
from rothetal_pkg.fiji import t2

# CSV path.
CSV_PATH = os.path.join(ROOT_DIR, r'CSVs')

csv_base = t2.get_project().getTitle().replace('RRJD', 'brain').replace('.xml', '')

SECTION_THICKNESS = 40
DOWNSAMPLING = 4.

print t2.get_project()  # Double check correct project is open.
cal = t2.get_calibration()
patches = t2.get_all_patches()
atdict = {int(round(cal.getX(patch.getLayer().getZ()) / SECTION_THICKNESS)):patch.getAffineTransform() for patch in patches}
pdict = {int(round(cal.getX(patch.getLayer().getZ()) / SECTION_THICKNESS)):patch for patch in patches}

zs = [z + zoff for z in xlsvals[0::3]]  # leave zs as cell count numbers until later
xs = [(x + xoff - offsets[z + offsets_shift][0])/DOWNSAMPLING for x, z in zip(xlsvals[1::3], zs)]  # factor in downsampling of t2 project
ys = [(y + yoff - offsets[z + offsets_shift][1])/DOWNSAMPLING for y, z in zip(xlsvals[2::3], zs)]  # factor in downsampling of t2 project

zdict = {z:[] for z in set(zs)}
for z, x, y in zip(zs, xs, ys):
    zdict[z] += [x, y]
  
for z in zdict:
    zdict[z] = array('d', zdict[z])
    atdict[z].transform(zdict[z], 0, zdict[z], 0, len(zdict[z])//2)

c_out = 'AP,DV,LM\n'

for z in sorted(zdict.keys()):
    for x, y in zip(zdict[z][0::2], zdict[z][1::2]):
        c_out += '\n'.join(['%d,%0.6f,%0.6f' % ((z-1)*SECTION_THICKNESS, cal.getX(y), cal.getX(x))])  # NOTE FLIPPED X/Y, AND 1- to 0- Z-index!!
        c_out += '\n'

c_path = os.path.join(CSV_PATH, csv_base + '_cellcoords.csv')
c_file = open(c_path, 'w')
c_file.write(c_out)
c_file.close()
print('cell coords saved to %s' % c_path)